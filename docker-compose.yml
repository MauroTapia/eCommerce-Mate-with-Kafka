version: '3.7'

services:

    redpanda:
        image: docker.redpanda.com/redpandadata/console
        hostname: redpanda
        container_name: redpanda
        ports:
            - "8080:8080"
        environment:
            KAFKA_BROKERS: kafka:29092,kafka2:29093
            KAFKA_TLS_INSECURESKIPTLSVERIFY: true
            KAFKA_SCHEMAREGISTRY_ENABLED: true
            KAFKA_SCHEMAREGISTRY_URLS: http://schema-registry:8081
            KAFKA_SCHEMAREGISTRY_USERNAME: client
            KAFKA_SCHEMAREGISTRY_PASSWORD: client
            KAFKA_SCHEMAREGISTRY_TLS_ENABLED: false
            KAFKA_SCHEMAREGISTRY_TLS_INSECURESKIPTLSVERIFY: true
        depends_on:
            - kafka
            - kafka2
            - schema-registry
            - zookeeper
        restart: always
        networks:
            - kafka-mate

    zookeeper:
        image: confluentinc/cp-zookeeper:6.1.1
        hostname: zookeeper
        container_name: zookeeper
        ports:
            - "2181:2181"
        environment:
            ZOOKEEPER_CLIENT_PORT: 2181
            ZOOKEEPER_TICK_TIME: 2000
        restart: always
        networks:
            - kafka-mate

    kafka:
        image: confluentinc/cp-enterprise-kafka:6.1.1
        hostname: kafka
        container_name: kafka
        tmpfs: /kafka/kafka-logs
        depends_on:
            - zookeeper
        ports:
            - "9092:9092"
        environment:
            KAFKA_HEAP_OPTS: -Xmx3G -Xms1G
            KAFKA_BROKER_ID: 1
            KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
            KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
            KAFKA_DELETE_TOPIC_ENABLE: "true"
            KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
            KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
            KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
            KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
            KAFKA_LOG_RETENTION_MS: -1
            KAFKA_MESSAGE_MAX_BYTES: 10485880
            KAFKA_NUM_PARTITIONS: 1
            CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: kafka:9092
            CONFLUENT_METRICS_REPORTER_ZOOKEEPER_CONNECT: zookeeper:2181
            CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
            CONFLUENT_METRICS_ENABLE: "true"
            CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'
        volumes:
            - /var/run/docker.sock:/var/run/docker.sock
        restart: always
        networks:
            - kafka-mate

    kafka2:
        image: confluentinc/cp-enterprise-kafka:6.1.1
        hostname: kafka2
        container_name: kafka2
        tmpfs: /kafka/kafka-logs
        depends_on:
            - zookeeper
        ports:
            - "9093:9093"
        environment:
            KAFKA_HEAP_OPTS: -Xmx3G -Xms1G
            KAFKA_BROKER_ID: 2
            KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
            KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
            KAFKA_DELETE_TOPIC_ENABLE: "true"
            KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka2:29093,PLAINTEXT_HOST://localhost:9093
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
            KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
            KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
            KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
            KAFKA_LOG_RETENTION_MS: -1
            KAFKA_MESSAGE_MAX_BYTES: 10485880
            KAFKA_NUM_PARTITIONS: 1
            CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: kafka2:9093
            CONFLUENT_METRICS_REPORTER_ZOOKEEPER_CONNECT: zookeeper:2181
            CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
            CONFLUENT_METRICS_ENABLE: "true"
            CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'
        volumes:
            - /var/run/docker.sock:/var/run/docker.sock
        restart: always
        networks:
            - kafka-mate

    schema-registry:
        image: confluentinc/cp-schema-registry:6.1.1
        container_name: schema-registry
        ports:
            - "8081:8081"
        environment:
            SCHEMA_REGISTRY_HOST_NAME: schema-registry
            SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: zookeeper:2181
            SCHEMA_REGISTRY_LISTENERS: http://schema-registry:8081
        depends_on:
            - kafka
        restart: always
        networks:
            - kafka-mate

    enviador-promocion:
        build: ./enviador-promocion
        container_name: enviador-promocion
        restart: always
        ports:
          - "8090:8080"
        environment:
          - "kafka=kafka"
          - "schema-registry=schema-registry"
        healthcheck:
            test: [ "CMD-SHELL", "curl -f http://localhost:8082/actuator/health || exit 1" ]
            interval: 10s
            timeout: 5s
            retries: 3
            start_period: 30s
        networks:
            - kafka-mate

    transformador-productos:
        build: ./transformador-productos
        container_name: transformador-productos
        restart: always
        ports:
          - "8092:8080"
        environment:
          - "kafka=kafka"
          - "schema-registry=schema-registry"
        networks:
            - kafka-mate

    enviador-productos:
        build: ./enviador-productos
        container_name: enviador-productos
        restart: always
        ports:
          - "8091:8080"
        environment:
          - "kafka=kafka"
          - "schema-registry=schema-registry"
        healthcheck:
            test: [ "CMD-SHELL", "curl -f http://localhost:8082/actuator/health || exit 1" ]
            interval: 10s
            timeout: 5s
            retries: 3
            start_period: 30s
        networks:
            - kafka-mate

    aplicador-promociones:
        build: ./aplicador-promociones
        container_name: aplicador-promociones
        restart: always
        ports:
            - "8095:8080"
        environment:
            - "kafka=kafka"
            - "schema-registry=schema-registry"
        networks:
            - kafka-mate

    aplicador-ventas:
        build: ./aplicador-ventas
        container_name: aplicador-ventas
        restart: always
        ports:
            - "8098:8080"
        environment:
            - "kafka=kafka"
            - "schema-registry=schema-registry"
        networks:
            - kafka-mate

    enviador-ventas:
        build: ./enviador-ventas
        container_name: enviador-ventas
        restart: always
        ports:
            - "8097:8080"
        environment:
            - "kafka=kafka"
            - "schema-registry=schema-registry"
        healthcheck:
            test: [ "CMD-SHELL", "curl -f http://localhost:8082/actuator/health || exit 1" ]
            interval: 10s
            timeout: 5s
            retries: 3
            start_period: 30s
        networks:
            - kafka-mate

    agrupador-categoria:
        build: ./agrupador-categoria
        container_name: agrupador-categoria
        restart: always
        ports:
            - "8094:8080"
        environment:
            - "kafka=kafka"
            - "schema-registry=schema-registry"
        networks:
            - kafka-mate

    postgres:
        image: postgres:15
        container_name: postgres
        restart: always
        environment:
            POSTGRES_DB: mates_db
            POSTGRES_USER: user
            POSTGRES_PASSWORD: password
        ports:
            - 5432:5432
        networks:
            - kafka-mate
        volumes:
            - postgres-data:/var/lib/postgresql/data
        logging:
            options:
                max-size: "10m"
                max-file: "3"
        healthcheck:
            test: [ "CMD-SHELL" ]
            interval: 10s
            timeout: 5s
            retries: 5

    postgresVentas:
        image: postgres:15
        container_name: postgresVentas
        restart: always
        environment:
            POSTGRES_DB: ventas_db
            POSTGRES_USER: user
            POSTGRES_PASSWORD: password
        ports:
            - 5433:5433
        networks:
            - kafka-mate
        volumes:
            - postgres-data-ventas:/var/lib/postgresql/data
        logging:
            options:
                max-size: "10m"
                max-file: "3"
        healthcheck:
            test: [ "CMD-SHELL" ]
            interval: 10s
            timeout: 5s
            retries: 5

    consultador-mates:
        build: ./consultador-mates
        container_name: consultador-mates
        restart: always
        ports:
            - "8096:8080"
        environment:
            - "kafka=kafka"
            - "schema-registry=schema-registry"
        networks:
            - kafka-mate

    consultador-ventas:
        build: ./consultador-ventas
        container_name: consultador-ventas
        restart: always
        ports:
            - "8089:8080"
        environment:
            - "kafka=kafka"
            - "schema-registry=schema-registry"
        networks:
            - kafka-mate
#
    prometheus:
        image: prom/prometheus
        container_name: prometheus
        command:
            - '--config.file=/etc/prometheus/prometheus.yml'
            - '--storage.tsdb.path=/prometheus'
            - '--web.console.libraries=/etc/prometheus/console_libraries'
            - '--web.console.templates=/etc/prometheus/consoles'
            - '--web.enable-lifecycle'
        ports:
            - 9090:9090
        networks:
            - kafka-mate
        restart: unless-stopped
        volumes:
            - ./prometheus:/etc/prometheus
            - prom_data:/prometheus


    node-exporter:
        image: prom/node-exporter:latest
        container_name: node-exporter
        restart: unless-stopped
        volumes:
            - /proc:/host/proc:ro
            - /sys:/host/sys:ro
            - /:/rootfs:ro
        command:
            - '--path.procfs=/host/proc'
            - '--path.rootfs=/rootfs'
            - '--path.sysfs=/host/sys'
            - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc|/run/user)($$|/)`'
        expose:
            - 9100
        networks:
            - kafka-mate

    grafana:
        image: grafana/grafana
        container_name: grafana
        ports:
            - 3000:3000
        restart: unless-stopped
        environment:
            - GF_SECURITY_ADMIN_USER=admin
            - GF_SECURITY_ADMIN_PASSWORD=admin
        volumes:
            - ./grafana:/etc/grafana/provisioning/datasources
        networks:
            - kafka-mate

    postgresSonar:
        image: postgres:latest
        container_name: postgresSonar
        environment:
            POSTGRES_USER: sonar
            POSTGRES_PASSWORD: sonar
            POSTGRES_DB: sonarqube
        networks:
            - kafka-mate
        volumes:
            - postgres_dataSonar:/var/lib/postgresql/data


    sonarqube:
        image: sonarqube:lts
        container_name: sonarq
        networks:
            - kafka-mate
        depends_on:
            - postgres
        ports:
            - "9000:9000"
        environment:
            SONAR_JDBC_URL: jdbc:postgresql://postgresSonar:5432/sonarqube
            SONAR_JDBC_USERNAME: sonar
            SONAR_JDBC_PASSWORD: sonar
        volumes:
            - sonarqube_data:/opt/sonarqube/data
            - sonarqube_logs:/opt/sonarqube/logs
            - sonarqube_extensions:/opt/sonarqube/extensions


volumes:
    prom_data: {}
    postgres-data: {}
    postgres-data-ventas: {}
    postgres_dataSonar:
    sonarqube_data:
    sonarqube_logs:
    sonarqube_extensions:
    #    db: {}


networks:
    kafka-mate:
        name: kafka-mate